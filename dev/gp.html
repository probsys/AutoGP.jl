<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Gaussian Process Library · AutoGP</title><meta name="title" content="Gaussian Process Library · AutoGP"/><meta property="og:title" content="Gaussian Process Library · AutoGP"/><meta property="twitter:title" content="Gaussian Process Library · AutoGP"/><meta name="description" content="Documentation for AutoGP."/><meta property="og:description" content="Documentation for AutoGP."/><meta property="twitter:description" content="Documentation for AutoGP."/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="index.html"><img src="assets/logo.svg" alt="AutoGP logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="index.html">AutoGP</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="index.html">Home</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="tutorials/overview.html">Overview</a></li><li><a class="tocitem" href="tutorials/iclaims.html">Insurance Claims</a></li><li><a class="tocitem" href="tutorials/callbacks.html">Inspecting Online Inference</a></li><li><a class="tocitem" href="tutorials/decomposition.html">Time Series Decomposition</a></li><li><a class="tocitem" href="tutorials/greedy_mcmc.html">Greedy Search and MCMC</a></li></ul></li><li><a class="tocitem" href="api.html">AutoGP API</a></li><li class="is-active"><a class="tocitem" href="gp.html">Gaussian Process Library</a><ul class="internal"><li><a class="tocitem" href="#gp_cov_kernel"><span>Covariance Kernels</span></a></li><li><a class="tocitem" href="#gp_cov_kernel_prim"><span>Primitive Kernels</span></a></li><li><a class="tocitem" href="#gp_cov_kernel_comp"><span>Composite Kernels</span></a></li><li><a class="tocitem" href="#Prediction-Utilities"><span>Prediction Utilities</span></a></li><li><a class="tocitem" href="#Prior-Configuration"><span>Prior Configuration</span></a></li></ul></li><li><a class="tocitem" href="utils.html">Utilities</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href="gp.html">Gaussian Process Library</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="gp.html">Gaussian Process Library</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/probsys/AutoGP.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/probsys/AutoGP.jl/blob/main/docs/src/gp.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Gaussian-Process-Library"><a class="docs-heading-anchor" href="#Gaussian-Process-Library">Gaussian Process Library</a><a id="Gaussian-Process-Library-1"></a><a class="docs-heading-anchor-permalink" href="#Gaussian-Process-Library" title="Permalink"></a></h1><ul><li><a href="gp.html#Gaussian-Process-Library">Gaussian Process Library</a></li><li class="no-marker"><ul><li><a href="gp.html#gp_cov_kernel">Covariance Kernels</a></li><li><a href="gp.html#gp_cov_kernel_prim">Primitive Kernels</a></li><li><a href="gp.html#gp_cov_kernel_comp">Composite Kernels</a></li><li><a href="gp.html#Prediction-Utilities">Prediction Utilities</a></li><li><a href="gp.html#Prior-Configuration">Prior Configuration</a></li></ul></li></ul><p>This section describes a library for Gaussian process time series models. A technical overview of key concepts can be found in the following references.</p><blockquote><p>Roberts S, Osborne M, Ebden M, Reece S, Gibson N, Aigrain S. 2013. Gaussian processes for time-series modelling. Phil Trans R Soc A 371: 20110550. <a href="http://dx.doi.org/10.1098/rsta.2011.0550">http://dx.doi.org/10.1098/rsta.2011.0550</a></p></blockquote><blockquote><p>Rasmussen C, Williams C. 2006. Gaussian Processes for Machine Learning. MIT Press, Cambridge, MA. <a href="http://gaussianprocess.org/gpml/chapters/">http://gaussianprocess.org/gpml/chapters/</a></p></blockquote><article><details class="docstring" open="true"><summary id="AutoGP.GP"><a class="docstring-binding" href="#AutoGP.GP"><code>AutoGP.GP</code></a> — <span class="docstring-category">Module</span></summary><div><p>Module for Gaussian process modeling library.</p><a class="docs-sourcelink" target="_blank" href="https://github.com/probsys/AutoGP.jl/blob/a3058ade9e212549fe265fcbdb862654cc377362/src/GP.jl#L15">source</a></div></details></article><h2 id="gp_cov_kernel"><a class="docs-heading-anchor" href="#gp_cov_kernel">Covariance Kernels</a><a id="gp_cov_kernel-1"></a><a class="docs-heading-anchor-permalink" href="#gp_cov_kernel" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="AutoGP.GP.Node"><a class="docstring-binding" href="#AutoGP.GP.Node"><code>AutoGP.GP.Node</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">abstract type Node end</code></pre><p>Abstract class for <a href="gp.html#gp_cov_kernel">covariance kernels</a>.</p><a class="docs-sourcelink" target="_blank" href="https://github.com/probsys/AutoGP.jl/blob/a3058ade9e212549fe265fcbdb862654cc377362/src/GP.jl#L35-L38">source</a></div></details></article><article><details class="docstring" open="true"><summary id="AutoGP.GP.LeafNode"><a class="docstring-binding" href="#AutoGP.GP.LeafNode"><code>AutoGP.GP.LeafNode</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">abstract type LeafNode &lt;: Node end</code></pre><p>Abstract class for <a href="gp.html#gp_cov_kernel_prim">primitive covariance kernels</a>.</p><a class="docs-sourcelink" target="_blank" href="https://github.com/probsys/AutoGP.jl/blob/a3058ade9e212549fe265fcbdb862654cc377362/src/GP.jl#L41-L44">source</a></div></details></article><article><details class="docstring" open="true"><summary id="AutoGP.GP.BinaryOpNode"><a class="docstring-binding" href="#AutoGP.GP.BinaryOpNode"><code>AutoGP.GP.BinaryOpNode</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">abstract type BinaryOpNode &lt;: Node end</code></pre><p>Abstract class for [composite covariance kernels](@ref (@ref gp<em>cov</em>kernel_comp).</p><a class="docs-sourcelink" target="_blank" href="https://github.com/probsys/AutoGP.jl/blob/a3058ade9e212549fe265fcbdb862654cc377362/src/GP.jl#L47-L50">source</a></div></details></article><article><details class="docstring" open="true"><summary id="AutoGP.GP.pretty"><a class="docstring-binding" href="#AutoGP.GP.pretty"><code>AutoGP.GP.pretty</code></a> — <span class="docstring-category">Function</span></summary><div><pre><code class="language-julia hljs">pretty(node::Node)</code></pre><p>Return a pretty <code>String</code> representation of <code>node</code>.</p><a class="docs-sourcelink" target="_blank" href="https://github.com/probsys/AutoGP.jl/blob/a3058ade9e212549fe265fcbdb862654cc377362/src/GP.jl#L1000-L1003">source</a></div></details></article><article><details class="docstring" open="true"><summary id="Base.size"><a class="docstring-binding" href="#Base.size"><code>Base.size</code></a> — <span class="docstring-category">Function</span></summary><div><pre><code class="language-julia hljs">Base.size(node::Node)
Base.size(node::LeafNode) = 1
Base.size(a::LeafNode, b::Node) = size(a) + size(b)</code></pre><p>Return the total number of subexpressions in a <a href="gp.html#AutoGP.GP.Node"><code>Node</code></a>, as defined above.</p><a class="docs-sourcelink" target="_blank" href="https://github.com/probsys/AutoGP.jl/blob/a3058ade9e212549fe265fcbdb862654cc377362/src/GP.jl#L87-L92">source</a></div></details></article><article><details class="docstring" open="true"><summary id="AutoGP.GP.eval_cov"><a class="docstring-binding" href="#AutoGP.GP.eval_cov"><code>AutoGP.GP.eval_cov</code></a> — <span class="docstring-category">Function</span></summary><div><pre><code class="language-julia hljs">eval_cov(node::Node, t1::Real, t2::Real)
eval_cov(node::Node, ts::Vector{Float64})</code></pre><p>Evaluate the covariance function <code>node</code> at the given time indexes. The first form returns a <code>Real</code> number and the second form returns a covariance <code>Matrix</code>.</p><a class="docs-sourcelink" target="_blank" href="https://github.com/probsys/AutoGP.jl/blob/a3058ade9e212549fe265fcbdb862654cc377362/src/GP.jl#L53-L60">source</a></div></details></article><article><details class="docstring" open="true"><summary id="AutoGP.GP.compute_cov_matrix"><a class="docstring-binding" href="#AutoGP.GP.compute_cov_matrix"><code>AutoGP.GP.compute_cov_matrix</code></a> — <span class="docstring-category">Function</span></summary><div><pre><code class="language-julia hljs">compute_cov_matrix(node::Node, noise, ts)</code></pre><p>Non-vectorized implementation of <a href="gp.html#AutoGP.GP.compute_cov_matrix_vectorized"><code>compute_cov_matrix_vectorized</code></a>.</p><a class="docs-sourcelink" target="_blank" href="https://github.com/probsys/AutoGP.jl/blob/a3058ade9e212549fe265fcbdb862654cc377362/src/GP.jl#L656-L659">source</a></div></details></article><article><details class="docstring" open="true"><summary id="AutoGP.GP.compute_cov_matrix_vectorized"><a class="docstring-binding" href="#AutoGP.GP.compute_cov_matrix_vectorized"><code>AutoGP.GP.compute_cov_matrix_vectorized</code></a> — <span class="docstring-category">Function</span></summary><div><pre><code class="language-julia hljs">compute_cov_matrix_vectorized(node::Node, noise, ts)</code></pre><p>Compute covariance matrix by evaluating <code>node</code> on all pair of <code>ts</code>. The <code>noise</code> is added to the diagonal of the covariance matrix, which means that if <code>ts[i] == ts[j]</code>, then <code>X[ts[i]]</code> and <code>Xs[ts[j]]</code> are i.i.d. samples of the true function at <code>ts[i]</code> plus mean zero Gaussian noise.</p><a class="docs-sourcelink" target="_blank" href="https://github.com/probsys/AutoGP.jl/blob/a3058ade9e212549fe265fcbdb862654cc377362/src/GP.jl#L644-L651">source</a></div></details></article><article><details class="docstring" open="true"><summary id="AutoGP.GP.extract_kernel"><a class="docstring-binding" href="#AutoGP.GP.extract_kernel"><code>AutoGP.GP.extract_kernel</code></a> — <span class="docstring-category">Function</span></summary><div><pre><code class="language-julia hljs">extract_kernel(node::Node, ::Type{T}; retain::Bool=false) where T&lt;:LeafNode</code></pre><p>Retain only those primitive kernels in <code>node</code> of type <code>T &lt;: LeafNode</code>, by replacing all other primitive kernels with an appropriate dummy kernel:</p><ul><li><a href="gp.html#AutoGP.GP.Constant"><code>Constant</code></a><code>(0)</code> for <a href="gp.html#AutoGP.GP.Plus"><code>Plus</code></a></li><li><a href="gp.html#AutoGP.GP.Constant"><code>Constant</code></a><code>(0)</code> for <a href="gp.html#AutoGP.GP.ChangePoint"><code>ChangePoint</code></a></li><li><a href="gp.html#AutoGP.GP.Constant"><code>Constant</code></a><code>(1)</code> for <a href="gp.html#AutoGP.GP.Plus"><code>Plus</code></a>.</li></ul><p>If all primitive kernels in <code>node</code> are of type <code>T</code>, the return value is <code>Constant(0)</code>.</p><p>If <code>retain=false</code> then the behavior is flipped: the primitive kernels of type <code>T</code> are removed, while the others are retained.</p><a class="docs-sourcelink" target="_blank" href="https://github.com/probsys/AutoGP.jl/blob/a3058ade9e212549fe265fcbdb862654cc377362/src/GP.jl#L519-L532">source</a></div></details></article><article><details class="docstring" open="true"><summary id="AutoGP.GP.split_kernel_sop"><a class="docstring-binding" href="#AutoGP.GP.split_kernel_sop"><code>AutoGP.GP.split_kernel_sop</code></a> — <span class="docstring-category">Function</span></summary><div><pre><code class="language-julia hljs">split_kernel_sop(node::Node, ::Type{T}) where T&lt;:LeafNode</code></pre><p>Splits the kernel <span>$k$</span> denoted by <code>node</code> according to a sum-of-products interpretation. In particular, write</p><p class="math-container">\[k = k_{11}k_{12}\cdots k_{1n_1} + k_{21}k_{22}\cdots k_{2n_2} + \dots + k_{m1}k_{m2}\cdots k_{m n_m}.\]</p><p>For a given primitive base kernel type <code>T</code> we can rewrite the above expression as</p><p class="math-container">\[k = k^{\rm T} + k^{\rm nT},\]</p><p>where <span>$k^{\rm T}$</span> contains all addends with a factor of type <code>T</code>, and <span>$k^{\rm nT}$</span> are the addends without a factor of type <code>T</code>.</p><p>The function returns a pair <code>(node_a, node_b)</code> corresponding to <span>$k^{\rm T}$</span> and <span>$k^{\rm nT}$</span> above, with <code>Constant(0)</code> serving as the sentinel value.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">julia&gt; l = Linear(1); p = Periodic(1,1); c = Constant(1)
julia&gt; split_kernel_sop(l, Linear)
(l, Constant(0))
julia&gt; split_kernel_sop(l, Periodic)
(Constant(0), l)
julia&gt; split_kernel_sop(l*p + l*c, Periodic)
(l*p, l*c)
julia&gt; split_kernel_sop(p*p, Periodic)
(p*p, Constant(0))</code></pre><a class="docs-sourcelink" target="_blank" href="https://github.com/probsys/AutoGP.jl/blob/a3058ade9e212549fe265fcbdb862654cc377362/src/GP.jl#L565-L600">source</a></div></details></article><article><details class="docstring" open="true"><summary id="AutoGP.GP.reparameterize"><a class="docstring-binding" href="#AutoGP.GP.reparameterize"><code>AutoGP.GP.reparameterize</code></a> — <span class="docstring-category">Function</span></summary><div><pre><code class="language-julia hljs">reparameterize(node::Node, t::LinearTransform)</code></pre><p>Reparameterize the covariance kernel according to the given <a href="utils.html#AutoGP.Transforms.LinearTransform-Tuple{Vector{&lt;:Real}, Any, Any}"><code>LinearTransform</code></a> applied to the input (known as an &quot;input warping&quot;). For a kernel <span>$k(\cdot,\cdot; \theta)$</span> and a linear transform <span>$f(t) = at+b$</span> over the time domain, this function returns a kernel with new parameters <span>$\theta&#39;$</span> such that <span>$k(at+b, au+b; \theta) = k(t, u; \theta&#39;)$</span>.</p><a class="docs-sourcelink" target="_blank" href="https://github.com/probsys/AutoGP.jl/blob/a3058ade9e212549fe265fcbdb862654cc377362/src/GP.jl#L63-L72">source</a></div></details></article><article><details class="docstring" open="true"><summary id="AutoGP.GP.rescale"><a class="docstring-binding" href="#AutoGP.GP.rescale"><code>AutoGP.GP.rescale</code></a> — <span class="docstring-category">Function</span></summary><div><pre><code class="language-julia hljs">rescale(node::Node, t::LinearTransform)</code></pre><p>Rescale the covariance kernel according to the given <a href="utils.html#AutoGP.Transforms.LinearTransform-Tuple{Vector{&lt;:Real}, Any, Any}"><code>LinearTransform</code></a> applied to the output. In particular, for a GP <span>$X \sim \mathrm{GP}(0, k(\cdot,\cdot; \theta))$</span> and a transformation <span>$Y = aX + b$</span>, this function returns a kernel with new parameters <span>$\theta&#39;$</span> such that <span>$Y \sim \mathrm{GP}(b, k(\cdot,\cdot; \theta&#39;))$</span>.</p><a class="docs-sourcelink" target="_blank" href="https://github.com/probsys/AutoGP.jl/blob/a3058ade9e212549fe265fcbdb862654cc377362/src/GP.jl#L75-L84">source</a></div></details></article><h2 id="gp_cov_kernel_prim"><a class="docs-heading-anchor" href="#gp_cov_kernel_prim">Primitive Kernels</a><a id="gp_cov_kernel_prim-1"></a><a class="docs-heading-anchor-permalink" href="#gp_cov_kernel_prim" title="Permalink"></a></h2><p><strong>Notation</strong>. In this section, generic parameters (e.g., <span>$\theta$</span>, <span>$\theta_1$</span>, <span>$\theta_2$</span>), are used to denote fieldnames of the corresponding Julia structs in the same order as they appear in the constructors.</p><article><details class="docstring" open="true"><summary id="AutoGP.GP.WhiteNoise"><a class="docstring-binding" href="#AutoGP.GP.WhiteNoise"><code>AutoGP.GP.WhiteNoise</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">WhiteNoise(value)</code></pre><p>White noise covariance kernel.</p><p class="math-container">\[k(t, t&#39;) = \mathbf{I}[t = t&#39;] \theta\]</p><p>The random variables <span>$X[t]$</span> and <span>$X[t&#39;]$</span> are perfectly correlated whenever <span>$t = t&#39;$</span> and independent otherwise. This kernel cannot be used to represent the joint distribution of multiple i.i.d. measurements of <span>$X[t]$</span>, instead see <a href="gp.html#AutoGP.GP.compute_cov_matrix_vectorized"><code>compute_cov_matrix_vectorized</code></a>.</p><a class="docs-sourcelink" target="_blank" href="https://github.com/probsys/AutoGP.jl/blob/a3058ade9e212549fe265fcbdb862654cc377362/src/GP.jl#L116-L130">source</a></div></details></article><article><details class="docstring" open="true"><summary id="AutoGP.GP.Constant"><a class="docstring-binding" href="#AutoGP.GP.Constant"><code>AutoGP.GP.Constant</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">Constant(value)</code></pre><p>Constant covariance kernel.</p><p class="math-container">\[k(t,t&#39;) = \theta\]</p><p>Draws from this kernel are horizontal lines, where <span>$\theta$</span> determines the variance of the constant value around the mean (typically zero).</p><a class="docs-sourcelink" target="_blank" href="https://github.com/probsys/AutoGP.jl/blob/a3058ade9e212549fe265fcbdb862654cc377362/src/GP.jl#L145-L156">source</a></div></details></article><article><details class="docstring" open="true"><summary id="AutoGP.GP.Linear"><a class="docstring-binding" href="#AutoGP.GP.Linear"><code>AutoGP.GP.Linear</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">Linear(intercept[, bias=1, amplitude=1])</code></pre><p>Linear covariance kernel.</p><p class="math-container">\[k(t, t&#39;) = \theta_2 + \theta_3 (t - \theta_1)(t&#39;-\theta_1)\]</p><p>Draws from this kernel are sloped lines in the 2D plane. The time intercept is <span>$\theta_1$</span>. The variance around the time intercept is <span>$\theta_2$</span>. The scale factor, which dictates the slope, is <span>$\theta_3$</span>.</p><a class="docs-sourcelink" target="_blank" href="https://github.com/probsys/AutoGP.jl/blob/a3058ade9e212549fe265fcbdb862654cc377362/src/GP.jl#L171-L184">source</a></div></details></article><article><details class="docstring" open="true"><summary id="AutoGP.GP.SquaredExponential"><a class="docstring-binding" href="#AutoGP.GP.SquaredExponential"><code>AutoGP.GP.SquaredExponential</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">SquaredExponential(lengthscale[, amplitude=1])</code></pre><p>Squared Exponential covariance kernel.</p><p class="math-container">\[k(t,t&#39;) = \theta_2 \exp\left(-1/2|t-t&#39;|/\theta_2)^2 \right)\]</p><p>Draws from this kernel are smooth functions.</p><a class="docs-sourcelink" target="_blank" href="https://github.com/probsys/AutoGP.jl/blob/a3058ade9e212549fe265fcbdb862654cc377362/src/GP.jl#L217-L227">source</a></div></details></article><article><details class="docstring" open="true"><summary id="AutoGP.GP.GammaExponential"><a class="docstring-binding" href="#AutoGP.GP.GammaExponential"><code>AutoGP.GP.GammaExponential</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">GammaExponential(lengthscale, gamma[, amplitude=1])</code></pre><p>Gamma Exponential covariance kernel.</p><p class="math-container">\[k(t,t&#39;) = \theta_3 \exp(-(|t-t&#39;|/\theta_1)^{\theta_2})\]</p><p>Requires <code>0 &lt; gamma &lt;= 2</code>. Recovers the <a href="gp.html#AutoGP.GP.SquaredExponential"><code>SquaredExponential</code></a> kernel when <code>gamma = 2</code>.</p><a class="docs-sourcelink" target="_blank" href="https://github.com/probsys/AutoGP.jl/blob/a3058ade9e212549fe265fcbdb862654cc377362/src/GP.jl#L257-L268">source</a></div></details></article><article><details class="docstring" open="true"><summary id="AutoGP.GP.Periodic"><a class="docstring-binding" href="#AutoGP.GP.Periodic"><code>AutoGP.GP.Periodic</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">Periodic(lengthscale, period[, amplitude=1])</code></pre><p>Periodic covariance kernel.</p><p class="math-container">\[k(t,t&#39;) = \exp\left( (-2/\theta_1^2) \sin^2((\pi/\theta_2) |t-t&#39;|) \right)\]</p><p>The lengthscale determines how smooth the periodic function is within each period. Heuristically, the periodic kernel can be understood as:</p><ol><li>Sampling <span>$[X(t), t \in [0,p]] \sim \mathrm{GP}(0, \mathrm{SE}(\theta_1))$</span>.</li><li>Repeating this fragment for all intervals <span>$[jp, (j+1)p], j \in \mathbb{Z}$</span>.</li></ol><a class="docs-sourcelink" target="_blank" href="https://github.com/probsys/AutoGP.jl/blob/a3058ade9e212549fe265fcbdb862654cc377362/src/GP.jl#L301-L314">source</a></div></details></article><h2 id="gp_cov_kernel_comp"><a class="docs-heading-anchor" href="#gp_cov_kernel_comp">Composite Kernels</a><a id="gp_cov_kernel_comp-1"></a><a class="docs-heading-anchor-permalink" href="#gp_cov_kernel_comp" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="AutoGP.GP.Times"><a class="docstring-binding" href="#AutoGP.GP.Times"><code>AutoGP.GP.Times</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">Times(left::Node, right::Node)
Base.:*(left::Node, right::Node)</code></pre><p>Covariance kernel obtained by multiplying two covariance kernels pointwise.</p><p class="math-container">\[k(t,t&#39;) = k_{\rm left}(t,t&#39;) \times k_{\rm right}(t,t&#39;)\]</p><a class="docs-sourcelink" target="_blank" href="https://github.com/probsys/AutoGP.jl/blob/a3058ade9e212549fe265fcbdb862654cc377362/src/GP.jl#L394-L403">source</a></div></details></article><article><details class="docstring" open="true"><summary id="AutoGP.GP.Plus"><a class="docstring-binding" href="#AutoGP.GP.Plus"><code>AutoGP.GP.Plus</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">Plus(left::Node, right::Node)
Base.:+(left::Node, right::Node)</code></pre><p>Covariance kernel obtained by summing two covariance kernels pointwise.</p><p class="math-container">\[k(t,t&#39;) = k_{\rm left}(t,t&#39;) + k_{\rm right}(t,t&#39;)\]</p><a class="docs-sourcelink" target="_blank" href="https://github.com/probsys/AutoGP.jl/blob/a3058ade9e212549fe265fcbdb862654cc377362/src/GP.jl#L348-L357">source</a></div></details></article><article><details class="docstring" open="true"><summary id="AutoGP.GP.ChangePoint"><a class="docstring-binding" href="#AutoGP.GP.ChangePoint"><code>AutoGP.GP.ChangePoint</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">ChangePoint(left::Node, right::Node, location::Real, scale::Real)</code></pre><p>Covariance kernel obtained by switching between two kernels at <code>location</code>.</p><p class="math-container">\[\begin{aligned}
k(t,t&#39;) &amp;= [\sigma_1 \cdot k_{\rm left}(t, t&#39;) \cdot \sigma_2] + [(1 - \sigma_1) \cdot k_{\rm right}(t, t&#39;) \cdot (1-\sigma_2)] \\
\mathrm{where}\,
\sigma_1 &amp;= (1 + \tanh((t - \theta_1) / \theta_2))/2, \\
\sigma_2 &amp;= (1 + \tanh((t&#39; - \theta_1) / \theta_2))/2.
\end{aligned}\]</p><p>The <code>location</code> parameter <span>$\theta_1$</span> denotes the time point at which the change occurs.  The <code>scale</code> parameter <span>$\theta_2$</span> is a nonnegative number that controls the rate of change; its behavior can be understood by analyzing the two extreme values:</p><ul><li><p>If <code>location=0</code> then <span>$k_{\rm left}$</span> is active and <span>$k_{\rm right}$</span> is inactive for all times less than <code>location</code>; <span>$k_{\rm right}$</span> is active and <span>$k_{\rm left}$</span> is inactive for all times greater than <code>location</code>; and <span>$X[t] \perp X[t&#39;]$</span> for all <span>$t$</span> and <span>$t&#39;$</span> on opposite sides of <code>location</code>.</p></li><li><p>If <code>location=Inf</code> then <span>$k_{\rm left}$</span> and <span>$k_{\rm right}$</span> have equal effect for all time points, and <span>$k(t,t&#39;) = 1/2 (k_{\rm left}(t,&#39;t) + k_{\rm right}(t,t&#39;))$</span>, which is equivalent to a <a href="gp.html#AutoGP.GP.Plus"><code>Plus</code></a> kernel scaled by a factor of <span>$1/2$</span>.</p></li></ul><a class="docs-sourcelink" target="_blank" href="https://github.com/probsys/AutoGP.jl/blob/a3058ade9e212549fe265fcbdb862654cc377362/src/GP.jl#L438-L465">source</a></div></details></article><h2 id="Prediction-Utilities"><a class="docs-heading-anchor" href="#Prediction-Utilities">Prediction Utilities</a><a id="Prediction-Utilities-1"></a><a class="docs-heading-anchor-permalink" href="#Prediction-Utilities" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="Distributions.MvNormal"><a class="docstring-binding" href="#Distributions.MvNormal"><code>Distributions.MvNormal</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">dist = Distributions.MvNormal(
        node::Node,
        noise::Float64,
        ts::Vector{Float64},
        xs::Vector{Float64},
        ts_pred::Vector{Float64};
        noise_pred::Union{Nothing,Float64}=nothing)</code></pre><p>Return <a href="https://juliastats.org/Distributions.jl/stable/multivariate/#Distributions.MvNormal"><code>MvNormal</code></a> posterior predictive distribution over <code>xs_pred</code> at time indexes <code>ts_pred</code>, given noisy observations <code>[ts, xs]</code> and covariance function <code>node</code> with given level of observation <code>noise</code>. The model is</p><p class="math-container">\[\begin{aligned}
    \begin{bmatrix}
        X(\mathbf{t})\\
        X(\mathbf{t}^*)
    \end{bmatrix}
\sim \mathrm{MultivariteNormal} \left(
    \mathbf{0},
    \begin{bmatrix}
        k(\mathbf{t}, \mathbf{t}) + \eta I &amp; k(\mathbf{t}, \mathbf{t}^*) \\
        k(\mathbf{t}^*, \mathbf{t}) + \eta I &amp; k(\mathbf{t}^*, \mathbf{t}^*) + \eta^* I
    \end{bmatrix}
    \right).
\end{aligned}\]</p><p>The function returns the conditional multivariate normal distribution</p><p class="math-container">\[X(\mathbf{t}^*) \mid X(\mathbf{t}) = x(\mathbf{t}).\]</p><p>By default, the observation noise (<code>noise_pred</code>) of the new data is equal to the <code>noise</code> of the observed data; use <code>noise_pred = 0.</code> to obtain the predictive distribution over noiseless future values.</p><p><strong>See also</strong></p><ul><li>To compute log probabilities, <a href="https://juliastats.org/Distributions.jl/v0.24/multivariate/#Distributions.logpdf-Tuple{MultivariateDistribution{S}%20where%20S%3C:ValueSupport,%20AbstractArray}"><code>Distributions.logpdf</code></a></li><li>To generate samples, <a href="https://juliastats.org/Distributions.jl/stable/multivariate/#Base.rand-Tuple{AbstractRNG,%20MultivariateDistribution}"><code>Base.rand</code></a></li><li>To compute quantiles, <a href="gp.html#Statistics.quantile"><code>Distributions.quantile</code></a></li></ul><a class="docs-sourcelink" target="_blank" href="https://github.com/probsys/AutoGP.jl/blob/a3058ade9e212549fe265fcbdb862654cc377362/src/GP.jl#L672-L716">source</a></div></details></article><article><details class="docstring" open="true"><summary id="Statistics.quantile"><a class="docstring-binding" href="#Statistics.quantile"><code>Statistics.quantile</code></a> — <span class="docstring-category">Function</span></summary><div><pre><code class="language-julia hljs">Distributions.quantile(dist::Distributions.MvNormal, p)</code></pre><p>Compute quantiles of marginal distributions of <code>dist</code>.</p><p><strong>Examples</strong></p><pre><code class="language-example hljs">Distributions.quantile(Distributions.MvNormal([0,1,2,3], LinearAlgebra.I(4)), .5)
Distributions.quantile(Distributions.MvNormal([0,1,2,3], LinearAlgebra.I(4)), [[.1, .5, .9]])</code></pre><a class="docs-sourcelink" target="_blank" href="https://github.com/probsys/AutoGP.jl/blob/a3058ade9e212549fe265fcbdb862654cc377362/src/GP.jl#L982-L991">source</a></div></details></article><article><details class="docstring" open="true"><summary id="AutoGP.GP.infer_gp_sum"><a class="docstring-binding" href="#AutoGP.GP.infer_gp_sum"><code>AutoGP.GP.infer_gp_sum</code></a> — <span class="docstring-category">Function</span></summary><div><pre><code class="language-julia hljs">(mvn, indexes) = infer_gp_sum(
            nodes::Vector{Node},
            noise::Float64,
            ts::Vector{Float64},
            xs::Vector{Float64},
            ts_pred::Vector{Float64};
            noise_pred::Union{Nothing,Float64}=nothing)</code></pre><p>Consider a family of <span>$m$</span> independent Gaussian process kernels</p><p class="math-container">\[\begin{aligned}
F_i \sim \mathrm{GP}(\mathbf{0}, k_i) &amp;&amp; (1 \le i \le m).
\end{aligned}\]</p><p>and let <span>$\varepsilon(t)$</span> be an i.i.d. noise process with variance <span>$\eta$</span>.</p><p>Suppose we can observe the noisy sum of these latent GP functions:</p><p class="math-container">\[\begin{aligned}
X(t) = \sum_{i=1}^{m} F_i(t) + \varepsilon(t)
&amp;&amp;
X \sim \mathrm{GP}(0, k_1 + \dots + k_m + \eta).
\end{aligned}\]</p><p>Given observed data <span>$(\mathbf{t}, x(\mathbf{t}))$</span> and test points <span>$\mathbf{t}^*$</span>, this function computes the joint multivariate normal posterior over all unknown components</p><p class="math-container">\[\left[F_1(\mathbf{t}^*), \dots, F_m(\mathbf{t}^*), X(\mathbf{t}^*) \right]
    \mid X(\mathbf{t})=x(\mathbf{t}).\]</p><p>Inference is performed on the multivariate Gaussian system, which has a block diagonal structure</p><p class="math-container">\[\begin{aligned}
Z \coloneqq
    \begin{bmatrix}
        F_1(\mathbf{t}^*)   \\
        \vdots              \\
        F_m(\mathbf{t}^*)   \\
        X(\mathbf{t}^*)     \\
        X(\mathbf{t})
    \end{bmatrix},
&amp;&amp;
Z \sim \mathrm{MultivariteNormal}
    \left(
        \mathbf{0},
        \begin{bmatrix}
            \Sigma_{aa} &amp; \Sigma_{ab} \\
            \Sigma_{ba} &amp; \Sigma_{bb}
        \end{bmatrix}\right),
\end{aligned}\]</p><p>where</p><p class="math-container">\[\begin{aligned}
\Sigma_{aa} &amp;\coloneqq
    \begin{bmatrix}
        \mathrm{blkdiag}\left(
            k_1(\mathbf{t}^*,\mathbf{t}^*),
            \dots
            k_m(\mathbf{t}^*,\mathbf{t}^*)
            \right)
        &amp;
        \begin{matrix}
            k_1(\mathbf{t}^*,\mathbf{t}^*) \\
            \vdots \\
            k_m(\mathbf{t}^*,\mathbf{t}^*)
        \end{matrix}
    \\
        \begin{matrix}
            k_1(\mathbf{t}^*,\mathbf{t}^*) &amp;
            \dots &amp;
            k_m(\mathbf{t}^*,\mathbf{t}^*)
        \end{matrix}
        &amp;
        s(\mathbf{t}^*, \mathbf{t}^*) + \eta^*I
    \end{bmatrix},
\\[15pt]
\Sigma_{ab} &amp;\coloneqq
    \begin{bmatrix}
        k_1(\mathbf{t}^*, \mathbf{t}) \\
        \vdots \\
        k_m(\mathbf{t}^*, \mathbf{t}) \\
        s(\mathbf{t}^*, \mathbf{t})
    \end{bmatrix},
\quad
\Sigma_{ba} \coloneqq \Sigma_{ba}^{\top},
\\[15pt]
\Sigma_{bb} &amp;\coloneqq
    s(\mathbf{t}, \mathbf{t}) + \eta I,
\end{aligned}\]</p><p>with <span>$s(t,u) \coloneqq k_1(t,u) + \dots + k_m(t,u)$</span>.</p><p>The posterior is then</p><p class="math-container">\[\begin{aligned}
\mu_{a \mid b}   &amp;= \Sigma_{ab} \Sigma_{bb}^{-1} x(\mathbf{t}) \\
\Sigma_{a \mid b} &amp;= \Sigma_{aa} - \Sigma_{ab} \Sigma_{bb}^{-1} \Sigma_{ba}
\end{aligned}\]</p><p>Here, <code>nodes::Vector{Node}</code> is the list of covariance kernels for the latent GPs; <code>ts</code> and <code>xs</code> are the observed data, <code>noise</code> is the the observation noise, <code>ts_pred</code> are the test indexes. By default, the observation noise (<code>noise_pred</code>) of the test data is equal to the <code>noise</code> of the observed data; use <code>noise_pred = 0.</code> to obtain the predictive distribution over noiseless future values.</p><p>The return value <code>v</code> is a named tuple where</p><ul><li><p><code>v.mvn</code> an instance of <a href="https://juliastats.org/Distributions.jl/stable/multivariate/#Distributions.MvNormal"><code>MvNormal</code></a> for the posterior predictive.</p></li><li><p><code>v.indexes</code> is named tuple where</p><ul><li><p><code>v.indexes.F</code> are the indexes in the covariance matrix for the latent functions at the test points.</p></li><li><p><code>v.indexes.X</code> are the indexes in the covariance matrix for the observable functions at the test points.</p></li></ul></li></ul><p>For predictions on in-sample time points <code>ts</code>, include all the requested time points in  <code>ts_pred</code>.</p><p><strong>See also</strong></p><ul><li>To compute log probabilities, <a href="https://juliastats.org/Distributions.jl/v0.24/multivariate/#Distributions.logpdf-Tuple{MultivariateDistribution{S}%20where%20S%3C:ValueSupport,%20AbstractArray}"><code>Distributions.logpdf</code></a></li><li>To generate samples, <a href="https://juliastats.org/Distributions.jl/stable/multivariate/#Base.rand-Tuple{AbstractRNG,%20MultivariateDistribution}"><code>Base.rand</code></a></li><li>To compute quantiles, <a href="gp.html#Statistics.quantile"><code>Distributions.quantile</code></a></li></ul><a class="docs-sourcelink" target="_blank" href="https://github.com/probsys/AutoGP.jl/blob/a3058ade9e212549fe265fcbdb862654cc377362/src/GP.jl#L748-L889">source</a></div></details></article><h2 id="Prior-Configuration"><a class="docs-heading-anchor" href="#Prior-Configuration">Prior Configuration</a><a id="Prior-Configuration-1"></a><a class="docs-heading-anchor-permalink" href="#Prior-Configuration" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="AutoGP.GP.GPConfig"><a class="docstring-binding" href="#AutoGP.GP.GPConfig"><code>AutoGP.GP.GPConfig</code></a> — <span class="docstring-category">Type</span></summary><div><pre><code class="language-julia hljs">config = GPConfig(kwargs...)</code></pre><p>Configuration of prior distribution over Gaussian process kernels, i.e., an instance of <a href="gp.html#AutoGP.GP.Node"><code>Node</code></a>. The main <code>kwargs</code> (all optional) are:</p><ul><li><p><code>node_dist_leaf::Vector{Real}</code>: Prior distribution over <a href="gp.html#AutoGP.GP.LeafNode"><code>LeafNode</code></a> kernels; default is uniform.</p></li><li><p><code>node_dist_nocp::Vector{Real}</code>: Prior distribution over <a href="gp.html#AutoGP.GP.BinaryOpNode"><code>BinaryOpNode</code></a> kernels; only used if <code>changepoints=false</code>.</p></li><li><p><code>node_dist_cp::Vector{Real}</code>: Prior distribution over <a href="gp.html#AutoGP.GP.BinaryOpNode"><code>BinaryOpNode</code></a> kernels; only used if <code>changepoints=true</code>.</p></li><li><p><code>max_depth::Integer</code>: Maximum depth of covariance node; default is <code>-1</code> for unbounded.</p></li><li><p><code>changepoints::Bool</code>: Whether to permit <a href="gp.html#AutoGP.GP.ChangePoint"><code>ChangePoint</code></a> compositions; default is <code>true</code>.</p></li><li><p><code>noise::Union{Nothing,Float64}</code>: Whether to use a fixed observation noise; default is <code>nothing</code> to infer automatically.</p></li></ul><a class="docs-sourcelink" target="_blank" href="https://github.com/probsys/AutoGP.jl/blob/a3058ade9e212549fe265fcbdb862654cc377362/src/GP.jl#L1061-L1084">source</a></div></details></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="api.html">« AutoGP API</a><a class="docs-footer-nextpage" href="utils.html">Utilities »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.0 on <span class="colophon-date" title="Monday 17 November 2025 16:28">Monday 17 November 2025</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
